def llm_intent_check(extracted_text, agent_goal):
    """
    Placeholder for LLM-based reasoning.
    In future, this will compare page instructions
    with agent goals to detect intent mismatch.
    """
    return {
        "intent_match": True,
        "confidence": 0.9
    }
